{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
        },
        {
            "name": "llm_judge.py",
            "type": "debugpy",
            "request": "launch",
            "program": "llm_judge.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--n_dataset_examples=3",
                "--n_samples_per_example=2",
                "--judge_model_id=Qwen/Qwen3-4B",
                "--gen_kwargs_str=set2",
                "--remote_call_concurrency=10",
                "--vllm.port=8000",
                "--vllm.start_server=False",
                "--vllm.enforce_eager=True",
                "--only_run_missing_examples=True",
                "--preds_dir=/mnt/disk16tb/globus_shared/from-lrz-ai-systems",
                "--tgt_file=judge-responses.jsonl",
                "--data_rank=0",
                "--data_world_size=1"
            ]
        },
        {
            "name": "inference.py",
            "type": "debugpy",
            "request": "launch",
            "program": "inference.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--model_id=Qwen/Qwen3-4B",
                "--vllm_start_server=False",
                "--gen_kwargs=thinking",
                "--datasets=CSC",
                "--template_ids=0,1,2,3,4",
                "--n_loops=10",
                "--splits=train",
                "--n_examples=100",
                "--n_fewshot_examples=0",
                "--only_run_missing_examples=true"
            ]
        },
        {
            "name": "Streamlit",
            "type": "debugpy",
            "request": "launch",
            "module": "streamlit",
            "args": [
                "run",
                "${workspaceFolder}/st_app/rate_reasoning.py"
            ],
            "console": "integratedTerminal",
            "justMyCode": false
        },
        {
            "name": "vLLM Server",
            "type": "debugpy",
            "request": "launch",
            "module": "vllm.entrypoints.openai.api_server",
            "args": [
                "--model=Qwen/Qwen3-4B",
                "--enable-reasoning",
                "--reasoning-parser=deepseek_r1",
                "--task=generate",
                "--max-model-len=16k",
                "--gpu-memory-utilization=0.8",
                "--enforce-eager"
            ],
            "justMyCode": false,
        },
    ]
}