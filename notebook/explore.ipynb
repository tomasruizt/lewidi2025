{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext cudf.pandas\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import load_dataset, enable_logging\n",
    "\n",
    "enable_logging()\n",
    "\n",
    "datasets = [\"CSC\", \"MP\", \"Paraphrase\", \"VariErrNLI\"]\n",
    "splits = [\"train\"]  # , \"dev\"]\n",
    "template_id = \"31\"\n",
    "run_name = \"allex_10loops\"\n",
    "ddf = pd.concat([load_dataset(d, split=s) for d in datasets for s in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from lewidi_lib import (\n",
    "    assign_col_template_alias,\n",
    "    process_rdf,\n",
    "    list_preds,\n",
    "    get_stable_random_subset,\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "preds_files_df = list_preds().query(\n",
    "    f\"split == 'train' and run_name == '{run_name}' and template_id == '{template_id}'\"\n",
    ")\n",
    "preds_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = preds_files_df[\"preds_file\"].tolist()\n",
    "rdf = duckdb.sql(f\"SELECT * FROM read_parquet({[str(f) for f in files]})\").df()\n",
    "print(len(rdf))\n",
    "indxs = (\n",
    "    rdf.groupby(\"dataset\", as_index=False)[\"dataset_idx\"]\n",
    "    .apply(get_stable_random_subset, n=2000)\n",
    "    .explode(\"dataset_idx\")\n",
    ")\n",
    "rdf = rdf.merge(indxs, on=[\"dataset\", \"dataset_idx\"], how=\"inner\")\n",
    "print(len(rdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = process_rdf(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf[\"dataset\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(context=\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "g = sns.relplot(\n",
    "    data=rdf,\n",
    "    x=\"model_size\",\n",
    "    y=\"is_valid_pred\",\n",
    "    hue=\"dataset\",\n",
    "    style=\"dataset\",\n",
    "    markers=[\"o\", \"s\", \"D\", \"P\"],\n",
    "    # row_order=[\"train\", \"dev\"],\n",
    "    kind=\"line\",\n",
    "    marker=\"o\",\n",
    "    height=3.5,\n",
    "    aspect=1.5,\n",
    ")\n",
    "g.set_axis_labels(\"Model Params [B]\", \"Valid Soft-Labels\")\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.grid(alpha=0.5)\n",
    "\n",
    "tgt_path = Path(\"./imgs/soft-label/valid_preds_by_model_size.pdf\")\n",
    "tgt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "g.figure.savefig(tgt_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\n",
    "    \"Dropping %d predictions that don't sum to 1\", len(rdf.query(\"~is_valid_pred\"))\n",
    ")\n",
    "rdf.query(\"is_valid_pred\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import assign_cols_perf_metrics_softlabel, join_dataset_and_preds\n",
    "\n",
    "joint_df = join_dataset_and_preds(ddf, rdf).pipe(assign_cols_perf_metrics_softlabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import (\n",
    "    compute_average_baseline_and_assing_perf_metrics,\n",
    "    compute_baseline_entropy,\n",
    "    compute_majority_baseline,\n",
    "    compute_target_entropy,\n",
    "    compute_unif_baseline_perf_metrics,\n",
    "    agg_perf_metrics,\n",
    "    compute_smoothed_baseline,\n",
    "    compute_best_wsloss_baseline,\n",
    ")\n",
    "\n",
    "\n",
    "majority_baseline = compute_majority_baseline(ddf)\n",
    "agg_majority_baseline = agg_perf_metrics(majority_baseline)\n",
    "average_baseline = compute_average_baseline_and_assing_perf_metrics(rdf)\n",
    "smoothed_baseline = compute_smoothed_baseline(rdf)\n",
    "best_wsloss_baseline = compute_best_wsloss_baseline(joint_df)\n",
    "unif_baseline_perf_metrics = compute_unif_baseline_perf_metrics(ddf)\n",
    "unif_baseline_entropy = compute_baseline_entropy(datasets)\n",
    "target_entropy = compute_target_entropy(ddf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is Performance Correlated With Size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from lewidi_lib import plot_horizontal_lines\n",
    "import seaborn as sns\n",
    "\n",
    "cols_ = [\n",
    "    \"template_id\",\n",
    "    \"model_id\",\n",
    "    \"model_size\",\n",
    "    \"gen_kwargs\",\n",
    "    \"dataset\",\n",
    "    \"ws_loss\",\n",
    "    \"pred_entropy\",\n",
    "]\n",
    "data_ = (\n",
    "    pd.concat(\n",
    "        [\n",
    "            joint_df[cols_].assign(Baseline=\"Simple\"),\n",
    "            average_baseline[cols_].assign(Baseline=\"Averaging\"),\n",
    "            smoothed_baseline[cols_].assign(Baseline=\"Smoothing\"),\n",
    "            best_wsloss_baseline[cols_].assign(Baseline=\"BoN Oracle\"),\n",
    "        ]\n",
    "    )\n",
    "    .pipe(assign_col_template_alias)\n",
    "    .query(f\"gen_kwargs == 'set2' and template_id == '{template_id}'\")\n",
    ")\n",
    "\n",
    "col_wrap = 2\n",
    "g = sns.relplot(\n",
    "    data=data_.query(\"Baseline != 'BoN Oracle'\"),\n",
    "    x=\"model_size\",\n",
    "    y=\"ws_loss\",\n",
    "    hue=\"Baseline\",\n",
    "    style=\"Baseline\",\n",
    "    markers=[\"o\", \"s\", \"D\"],\n",
    "    # col=\"template_alias\",\n",
    "    # col_order=sorted(data_[\"template_alias\"].unique()),\n",
    "    col=\"dataset\",\n",
    "    col_order=datasets,\n",
    "    col_wrap=col_wrap,\n",
    "    kind=\"line\",\n",
    "    # hue=\"gen_kwargs\",\n",
    "    # style=\"gen_kwargs\",\n",
    "    height=4.0,\n",
    "    aspect=1.2,\n",
    "    facet_kws={\"sharey\": False},\n",
    ")\n",
    "# g.set(ylim=(0, None))\n",
    "g.set_axis_labels(\"Model Params [B]\", \"Wasserstein Distance\")\n",
    "plot_horizontal_lines(\n",
    "    g,\n",
    "    unif_baseline_perf_metrics,\n",
    "    label=\"Uniform Baseline\",\n",
    "    color=\"blue\",\n",
    "    data_col=\"ws_loss\",\n",
    "    hpos=\"right\",\n",
    "    vpos=\"top\",\n",
    ")\n",
    "plot_horizontal_lines(\n",
    "    g,\n",
    "    agg_majority_baseline,\n",
    "    label=\"Majority Baseline\",\n",
    "    color=\"green\",\n",
    "    data_col=\"ws_loss\",\n",
    "    hpos=\"right\",\n",
    ")\n",
    "tgt_path = Path(\"./imgs/soft-label/baselines/ws_loss_vs_model_size.pdf\")\n",
    "tgt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "g.figure.savefig(tgt_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_32b = data_.query(\"model_id.str.contains('32B')\")\n",
    "method_order = [\"Simple\", \"Smoothing\", \"Averaging\", \"BoN Oracle\"]\n",
    "ws_loss_32b = duckdb.sql(\n",
    "    \"PIVOT data_32b ON dataset using mean(ws_loss) GROUP BY Baseline\"\n",
    ").df()\n",
    "ws_loss_32b = ws_loss_32b.set_index(\"Baseline\").loc[method_order].reset_index()\n",
    "ws_loss_32b.round(3).to_csv(\"tables/32b_ws_loss.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is performance correlated with avg entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_data_ = pd.concat(\n",
    "    [\n",
    "        joint_df.assign(Baseline=\"Simple\"),\n",
    "        average_baseline.assign(Baseline=\"Averaging\"),\n",
    "        smoothed_baseline.assign(Baseline=\"Smoothing\"),\n",
    "        # best_wsloss_baseline.assign(Baseline=\"BoN Oracle\"),\n",
    "    ]\n",
    ").query(f\"template_id == '{template_id}'\")\n",
    "\n",
    "g = sns.relplot(\n",
    "    data=ent_data_,\n",
    "    x=\"model_size\",\n",
    "    y=\"pred_entropy\",\n",
    "    hue=\"Baseline\",\n",
    "    style=\"Baseline\",\n",
    "    markers=[\"o\", \"s\", \"D\"],\n",
    "    # col=\"template_alias\",\n",
    "    # col_order=sorted(ent_data_[\"template_alias\"].unique()),\n",
    "    col=\"dataset\",\n",
    "    col_order=datasets,\n",
    "    col_wrap=col_wrap,\n",
    "    kind=\"line\",\n",
    "    marker=\"o\",\n",
    "    height=4.0,\n",
    "    aspect=1.2,\n",
    "    facet_kws={\"sharey\": False, \"sharex\": True},\n",
    ")\n",
    "g.set_axis_labels(\"Model Params [B]\", \"Avg. Entropy\")\n",
    "for ax in g.axes.flat:\n",
    "    ax.grid(alpha=0.5)\n",
    "plot_horizontal_lines(\n",
    "    g,\n",
    "    unif_baseline_entropy,\n",
    "    label=\"Uniform Entropy\",\n",
    "    color=\"blue\",\n",
    "    data_col=\"entropy\",\n",
    ")\n",
    "plot_horizontal_lines(\n",
    "    g,\n",
    "    target_entropy,\n",
    "    label=\"Human Entropy\",\n",
    "    color=\"green\",\n",
    "    data_col=\"entropy\",\n",
    "    pos=\"right\",\n",
    ")\n",
    "tgt_path = Path(\"./imgs/soft-label/baselines/entropy_vs_model_size.pdf\")\n",
    "tgt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "g.figure.savefig(tgt_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ent_df = joint_df.groupby(\n",
    "    [\"model_size\", \"gen_kwargs\", \"dataset\", \"split\"], as_index=False\n",
    ").agg(\n",
    "    avg_entropy=(\"pred_entropy\", \"mean\"),\n",
    "    avg_ws_loss=(\"ws_loss\", \"mean\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g = sns.relplot(\n",
    "    ent_df,\n",
    "    x=\"avg_entropy\",\n",
    "    y=\"avg_ws_loss\",\n",
    "    hue=\"model_size\",\n",
    "    style=\"gen_kwargs\",\n",
    "    col=\"split\",\n",
    "    # col_order=[\"train\", \"dev\"],\n",
    "    row=\"dataset\",\n",
    "    # row_order=[\"CSC\", \"MP\"],\n",
    "    kind=\"scatter\",\n",
    "    height=2.5,\n",
    "    aspect=1.2,\n",
    "    facet_kws={\"sharey\": False, \"sharex\": False},\n",
    "    palette=\"viridis\",\n",
    ")\n",
    "for ax in g.axes.flat:\n",
    "    ax.grid(alpha=0.5)\n",
    "plot_horizontal_lines(\n",
    "    g, unif_baseline_perf_metrics, label=\"Uniform Baseline\", color=\"blue\"\n",
    ")\n",
    "plot_horizontal_lines(g, strong_baselines, label=\"Gemini 2.5 Pro\", color=\"red\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
