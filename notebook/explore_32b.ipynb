{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext cudf.pandas\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import load_dataset, enable_logging\n",
    "\n",
    "enable_logging()\n",
    "\n",
    "datasets = [\"CSC\", \"Paraphrase\", \"MP\", \"VariErrNLI\"]\n",
    "splits = [\"train\"]  # , \"dev\"]\n",
    "if False:\n",
    "    task = \"perspectivist\"\n",
    "    template_ids = [\"63\"]\n",
    "else:\n",
    "    task = \"soft-label\"\n",
    "    template_ids = [\"60\"]\n",
    "run_name = \"1000ex_10loops\"\n",
    "\n",
    "ddf = pd.concat([load_dataset(d, split=s, task=task) for d in datasets for s in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "from lewidi_lib import process_rdf, list_preds\n",
    "\n",
    "preds_files_df = list_preds().query(\n",
    "    f\"split == 'train' and run_name == '{run_name}' and template_id.isin({template_ids}) and dataset in @datasets and exists and model_id == 'Qwen/Qwen3-32B'\"\n",
    ")\n",
    "preds_files_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import load_listof_parquets\n",
    "\n",
    "files = preds_files_df[\"preds_file\"].tolist()\n",
    "rdf = load_listof_parquets(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = process_rdf(rdf, response_contains_steps=True, task=task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf[\"dataset\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.groupby([\"dataset\", \"model_size\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(context=\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rdf.groupby(\"dataset\")[\"is_valid_pred\"].mean() * 100).reset_index().round(1).to_csv(\n",
    "    f\"./tables/{task}/32b_valid_preds_by_dataset.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\n",
    "    \"Dropping %d predictions that are not valid\", len(rdf.query(\"~is_valid_pred\"))\n",
    ")\n",
    "rdf.query(\"is_valid_pred\", inplace=True)\n",
    "rdf.groupby([\"dataset\", \"model_size\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import (\n",
    "    assign_col_avg_abs_dist,\n",
    "    assign_cols_perf_metrics,\n",
    "    join_dataset_and_preds,\n",
    ")\n",
    "\n",
    "joint_df = join_dataset_and_preds(ddf, rdf)\n",
    "joint_df = assign_cols_perf_metrics(joint_df, task=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import (\n",
    "    compute_average_baseline_and_assing_perf_metrics,\n",
    "    compute_baseline_entropy,\n",
    "    compute_maj_vote_baseline,\n",
    "    compute_majority_baseline,\n",
    "    compute_most_frequent_baseline,\n",
    "    compute_pe_rand_baseline,\n",
    "    compute_target_entropy,\n",
    "    compute_unif_baseline_perf_metrics,\n",
    "    agg_perf_metrics,\n",
    "    compute_smoothed_baseline,\n",
    "    compute_oracle_baseline,\n",
    ")\n",
    "\n",
    "if task == \"soft-label\":\n",
    "    perf_col = \"ws_loss\"\n",
    "    perf_col_label = \"Wasserstein Distance\"\n",
    "else:\n",
    "    perf_col = \"avg_abs_dist\"\n",
    "    perf_col_label = \"Absolute Dist.\"\n",
    "\n",
    "if task == \"soft-label\":\n",
    "    majority_baseline = compute_majority_baseline(ddf)\n",
    "    agg_majority_baseline = agg_perf_metrics(majority_baseline)\n",
    "    average_baseline = compute_average_baseline_and_assing_perf_metrics(rdf)\n",
    "    smoothed_baseline = compute_smoothed_baseline(rdf)\n",
    "    unif_baseline_perf_metrics = compute_unif_baseline_perf_metrics(ddf)\n",
    "    unif_baseline_entropy = compute_baseline_entropy(datasets)\n",
    "    target_entropy = compute_target_entropy(ddf)\n",
    "else:\n",
    "    rand_baseline = agg_perf_metrics(\n",
    "        compute_pe_rand_baseline(ddf), cols=[\"avg_abs_dist\"]\n",
    "    )\n",
    "    most_frequent_baseline = agg_perf_metrics(\n",
    "        compute_most_frequent_baseline(ddf), cols=[\"avg_abs_dist\"]\n",
    "    )\n",
    "    maj_vote_baseline = compute_maj_vote_baseline(joint_df)\n",
    "best_perf_baseline = compute_oracle_baseline(joint_df, perf_col=perf_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is Performance Correlated With Size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from lewidi_lib import plot_horizontal_lines\n",
    "import seaborn as sns\n",
    "\n",
    "cols_ = [\n",
    "    # \"model_id\",\n",
    "    # \"model_size\",\n",
    "    \"dataset\",\n",
    "    perf_col,\n",
    "]\n",
    "data_ = joint_df[cols_].assign(Baseline=\"Simple Sampling\")\n",
    "\n",
    "if task == \"soft-label\":\n",
    "    data_ = pd.concat(\n",
    "        [\n",
    "            # unif_baseline_perf_metrics[cols_].assign(Baseline=\"Uniform\"),\n",
    "            agg_majority_baseline[cols_].assign(Baseline=\"Most Frequent\"),\n",
    "            data_,\n",
    "            average_baseline[cols_].assign(Baseline=\"Model Averaging\"),\n",
    "            smoothed_baseline[cols_].assign(Baseline=\"Smoothing\"),\n",
    "            best_perf_baseline[cols_].assign(Baseline=\"BoN Oracle\"),\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    data_ = pd.concat(\n",
    "        [\n",
    "            most_frequent_baseline[cols_].assign(Baseline=\"Most Frequent\"),\n",
    "            data_,\n",
    "            maj_vote_baseline[cols_].assign(Baseline=\"Majority Vote\"),\n",
    "            best_perf_baseline[cols_].assign(Baseline=\"BoN Oracle\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "col_wrap = 2\n",
    "desired = [\n",
    "    \"Most Frequent\",\n",
    "    \"Simple Sampling\",\n",
    "    \"Model Averaging\",\n",
    "    \"BoN Oracle\",\n",
    "    \"Majority Vote\",\n",
    "]\n",
    "g = sns.catplot(\n",
    "    data_.query(\"Baseline in @desired\").reset_index(drop=True),\n",
    "    x=perf_col,\n",
    "    y=\"Baseline\",\n",
    "    hue=\"Baseline\",\n",
    "    col=\"dataset\",\n",
    "    col_wrap=2,\n",
    "    col_order=[\"CSC\", \"MP\", \"Paraphrase\", \"VariErrNLI\"],\n",
    "    kind=\"bar\",\n",
    "    sharex=False,\n",
    "    height=2.5,\n",
    "    aspect=1.8,\n",
    ")\n",
    "# g.set(ylim=(0, None))\n",
    "g.set_axis_labels(perf_col_label, \"\")\n",
    "# sns.move_legend(g, loc=\"lower left\", bbox_to_anchor=(0.1, 1.0), ncol=3)\n",
    "for ax in g.axes.flat:\n",
    "    ax.grid(alpha=0.5, axis=\"x\")\n",
    "\n",
    "if task == \"soft-label\":\n",
    "    g.axes[3].set_xlabel(\"Manhattan Distance\")\n",
    "else:\n",
    "    g.axes[3].set_xlabel(\"Error Rate\")\n",
    "\n",
    "tgt_path = Path(f\"./imgs/{task}/baselines/{perf_col}_32b.pdf\")\n",
    "tgt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "g.figure.savefig(tgt_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_32b = data_  # .query(\"model_id.str.contains('32B')\")\n",
    "if len(data_32b) == 0:\n",
    "    logger.warning(\"No 32B data found!\")\n",
    "else:\n",
    "    if task == \"soft-label\":\n",
    "        method_order = [\n",
    "            \"Simple Sampling\",\n",
    "            \"Most Frequent\",\n",
    "            \"Model Averaging\",\n",
    "            \"BoN Oracle\",\n",
    "        ]\n",
    "    else:\n",
    "        method_order = [\n",
    "            \"Simple Sampling\",\n",
    "            \"Most Frequent\",\n",
    "            \"Majority Vote\",\n",
    "            \"BoN Oracle\",\n",
    "        ]\n",
    "\n",
    "    perf_32b = duckdb.sql(\n",
    "        f\"PIVOT data_32b ON dataset using mean({perf_col}) GROUP BY Baseline\"\n",
    "    ).df()\n",
    "    perf_32b = perf_32b.set_index(\"Baseline\").loc[method_order].reset_index()\n",
    "    perf_32b.round(3).to_csv(f\"tables/{task}/32b_{perf_col}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is performance correlated with avg entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == \"soft-label\":\n",
    "    ent_data_ = pd.concat(\n",
    "        [\n",
    "            joint_df.assign(Baseline=\"Simple Sampling\"),\n",
    "            average_baseline.assign(Baseline=\"Model Averaging\"),\n",
    "            smoothed_baseline.assign(Baseline=\"Smoothing\"),\n",
    "            # best_wsloss_baseline.assign(Baseline=\"BoN Oracle\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    g = sns.catplot(\n",
    "        data=ent_data_.reset_index(drop=True),\n",
    "        x=\"pred_entropy\",\n",
    "        y=\"Baseline\",\n",
    "        hue=\"Baseline\",\n",
    "        # style=\"Baseline\",\n",
    "        # markers=[\"o\", \"s\", \"D\"],\n",
    "        # col=\"template_alias\",\n",
    "        # col_order=sorted(ent_data_[\"template_alias\"].unique()),\n",
    "        col=\"dataset\",\n",
    "        col_order=datasets,\n",
    "        col_wrap=col_wrap,\n",
    "        kind=\"bar\",\n",
    "        # marker=\"o\",\n",
    "        height=2.5,\n",
    "        aspect=1.6,\n",
    "        sharex=False,\n",
    "    )\n",
    "    # sns.move_legend(g, loc=\"lower left\", bbox_to_anchor=(0.2, 1.0), ncol=3)\n",
    "    g.set_axis_labels(\"Entropy\", \"\")\n",
    "    for ax in g.axes.flat:\n",
    "        ax.grid(alpha=0.5)\n",
    "    # plot_horizontal_lines(\n",
    "    #     g,\n",
    "    #     unif_baseline_entropy,\n",
    "    #     label=\"Uniform Entropy\",\n",
    "    #     color=\"blue\",\n",
    "    #     data_col=\"entropy\",\n",
    "    # )\n",
    "    # plot_horizontal_lines(\n",
    "    #     g,\n",
    "    #     target_entropy,\n",
    "    #     label=\"Human Entropy\",\n",
    "    #     color=\"green\",\n",
    "    #     data_col=\"entropy\",\n",
    "    #     pos=\"right\",\n",
    "    # )\n",
    "    tgt_path = Path(f\"./imgs/{task}/baselines/entropy_32b.pdf\")\n",
    "    tgt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    g.figure.savefig(tgt_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == \"soft-label\":\n",
    "    (\n",
    "        ent_data_.groupby(\"Baseline\")\n",
    "        .agg(\n",
    "            pred_entropy=(\"pred_entropy\", \"mean\"),\n",
    "            ws_loss=(\"ws_loss\", \"mean\"),\n",
    "        )\n",
    "        .sort_values(\"pred_entropy\")\n",
    "        * 100\n",
    "    ).round(1).to_csv(f\"./tables/{task}/32b_entropy_vs_perf.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
