{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5bc12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from logging import getLogger\n",
    "from lewidi_lib import enable_logging\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "enable_logging()\n",
    "logger = getLogger(__name__)\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import assert_path_exists, preds_file\n",
    "\n",
    "dataset = \"CSC\"\n",
    "task = \"soft-label\"\n",
    "file = preds_file(\n",
    "    dataset=dataset,\n",
    "    split=\"train\",\n",
    "    template=\"62\",\n",
    "    model_id=\"Qwen/Qwen3-14B\",\n",
    "    run_name=\"1000ex_10loops\",\n",
    ")\n",
    "rdf = pd.read_parquet(assert_path_exists(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ca6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import (\n",
    "    assign_cols_perf_metrics_softlabel,\n",
    "    compute_diversity_by_problem,\n",
    "    join_dataset,\n",
    "    keep_only_highest_diversity_problems,\n",
    "    process_rdf,\n",
    ")\n",
    "\n",
    "rdf = process_rdf(\n",
    "    rdf, task=task, response_contains_steps=True, discard_invalid_pred=True\n",
    ")\n",
    "if task == \"soft-label\":\n",
    "    answer_diversity = compute_diversity_by_problem(rdf)\n",
    "    rdf = rdf.merge(answer_diversity, on=\"dataset_idx\")\n",
    "len(rdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373584fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import assign_cols_perf_metrics\n",
    "\n",
    "\n",
    "joint_df = join_dataset(rdf, task=task)\n",
    "joint_df = assign_cols_perf_metrics(joint_df, task=task)\n",
    "\n",
    "if False:\n",
    "    joint_df_subset = keep_only_highest_diversity_problems(joint_df)\n",
    "else:\n",
    "    joint_df_subset = joint_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a69eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer_diversity.query(\"diversity == 'Q5'\")[[\"dataset_idx\", \"diversity\"]].to_parquet(\"high_diversity_ids.parquet\")\n",
    "\n",
    "# \"\"\"\n",
    "# copy (\n",
    "#     select rdf.*\n",
    "#     from (select * from '../../1000ex_10loops/preds/responses.parquet') as rdf\n",
    "#     join 'high_diversity_ids.parquet' as ids on rdf.dataset_idx = ids.dataset_idx\n",
    "#     )\n",
    "# to 'responses.parquet';\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9437c9",
   "metadata": {},
   "source": [
    "# Load Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import (\n",
    "    assign_col_response_parsed,\n",
    "    discard_na_response_rows,\n",
    "    process_ratings,\n",
    ")\n",
    "import numpy as np\n",
    "from prm800k import mapping\n",
    "\n",
    "# judge = \"gemini-2.5-flash\"\n",
    "# judge = \"Qwen/Qwen3-32B\"\n",
    "judge = \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\"\n",
    "# judge = \"qwen/qwen3-235b-a22b-2507\"\n",
    "# judge = \"Qwen/Qwen3-235B-A22B-Thinking-2507\"\n",
    "\n",
    "judge_file = {\n",
    "    \"gemini-2.5-flash\": \"gemini-2.5-flash/t24/responses.parquet\",\n",
    "    \"Qwen/Qwen3-32B\": \"Qwen/Qwen3-32B/set2/t24/1000ex_10loops_q5div/responses.parquet\",\n",
    "    \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\": \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B/set2/t24/1000ex_10loops_q5div/responses.parquet\",\n",
    "    \"qwen/qwen3-235b-a22b-2507\": \"qwen/qwen3-235b-a22b-2507/set2/t24/1000ex_10loops_q5div/responses.parquet\",\n",
    "    \"Qwen/Qwen3-235B-A22B-Thinking-2507\": \"Qwen/Qwen3-235B-A22B-Thinking-2507/set2/t24/1000ex_10loops_q5div/responses.parquet\",\n",
    "}\n",
    "ratings_file = file.parent.parent / \"judge\" / judge_file[judge]\n",
    "\n",
    "ratings = pd.read_parquet(ratings_file)\n",
    "logger.info(\n",
    "    \"Loaded %d ratings for %d different dataset_idxs\",\n",
    "    len(ratings),\n",
    "    ratings[\"dataset_idx\"].nunique(),\n",
    ")\n",
    "ratings = discard_na_response_rows(ratings)\n",
    "ratings = assign_col_response_parsed(ratings)\n",
    "ratings = process_ratings(\n",
    "    ratings, operation=np.mean, cat_mapping=mapping(ok=0.0, bad=0)\n",
    ")\n",
    "ratings = ratings[\n",
    "    [\"dataset_idx\", \"run_idx\", \"step_ratings\", \"score\", \"reasoning\", \"response_parsed\"]\n",
    "]\n",
    "ratings.rename(columns={\"reasoning\": \"judge_reasoning\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33260715",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_df_subset = joint_df_subset.merge(\n",
    "    ratings, on=[\"dataset_idx\", \"run_idx\"], how=\"left\"\n",
    ")\n",
    "joint_df_subset = discard_na_response_rows(joint_df_subset, col=\"score\")\n",
    "logger.info(\n",
    "    \"We have score for %d examples of %d different dataset_idxs\",\n",
    "    len(joint_df_subset),\n",
    "    joint_df_subset[\"dataset_idx\"].nunique(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83538c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import compute_n_steps_equality\n",
    "\n",
    "joint_df_subset = assign_col_response_parsed(joint_df_subset)\n",
    "compute_n_steps_equality(joint_df_subset, step_source=\"response_parsed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777c6ba9",
   "metadata": {},
   "source": [
    "# BoN Loss Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(joint_df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import bootstrap_avg\n",
    "\n",
    "if task == \"soft-label\":\n",
    "    perf_col = \"ws_loss\"\n",
    "else:\n",
    "    perf_col = \"avg_abs_dist\"\n",
    "\n",
    "np.random.seed(0)\n",
    "bootstrap_avg(\n",
    "    [\n",
    "        joint_df_subset.groupby(\"dataset_idx\").sample(n=1)[perf_col].mean()\n",
    "        for _ in range(100)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bff5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import select_max_score_df\n",
    "\n",
    "np.random.seed(0)\n",
    "bootstrap_avg(\n",
    "    [\n",
    "        select_max_score_df(joint_df_subset.sample(frac=1.0))[perf_col].mean()\n",
    "        for _ in range(20)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f72518",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle = joint_df_subset.loc[joint_df_subset.groupby(\"dataset_idx\")[perf_col].idxmin()]\n",
    "oracle[[perf_col, \"score\"]].apply(bootstrap_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b2fe66",
   "metadata": {},
   "source": [
    "# Problem-Level Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2f4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(df, perf_col: str):\n",
    "    coeff = np.corrcoef(df[\"score\"], df[perf_col])[0, 1]\n",
    "    return coeff\n",
    "\n",
    "\n",
    "corrs = (\n",
    "    joint_df_subset.groupby(\"dataset_idx\")[[\"score\", perf_col]]\n",
    "    .apply(corr, perf_col=perf_col)\n",
    "    .fillna(0)\n",
    ")\n",
    "bootstrap_avg(corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038420fe",
   "metadata": {},
   "source": [
    "# Individual Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f94a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_loss = joint_df_subset.loc[joint_df_subset.groupby(\"dataset_idx\")[\"ws_loss\"].idxmax()]\n",
    "# row = max_loss.iloc[0]\n",
    "# print(row[\"response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae4464c",
   "metadata": {},
   "source": [
    "# Aggregate Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ec31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(joint_df_subset, x=\"score\")\n",
    "ax.grid(alpha=0.5, axis=\"y\")\n",
    "ax.figure.set_size_inches(6, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a8ef78",
   "metadata": {},
   "source": [
    "# How does performance change with the number of samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a879f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import (\n",
    "    assign_col_avg_abs_dist,\n",
    "    compute_average_baseline_and_assing_perf_metrics,\n",
    "    compute_maj_vote_baseline,\n",
    "    compute_oracle_baseline,\n",
    ")\n",
    "\n",
    "\n",
    "if task == \"soft-label\":\n",
    "    baseline_df = compute_average_baseline_and_assing_perf_metrics(joint_df_subset)\n",
    "else:\n",
    "    baseline_df = compute_maj_vote_baseline(joint_df_subset)\n",
    "    baseline_df = assign_col_avg_abs_dist(baseline_df)\n",
    "\n",
    "baseline_perf = baseline_df[perf_col].mean()\n",
    "oracle = compute_oracle_baseline(joint_df_subset, perf_col=perf_col)\n",
    "oracle[[perf_col, \"score\"]].apply(bootstrap_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import compute_oracle_baseline\n",
    "\n",
    "oracle_ws_loss = compute_oracle_baseline(joint_df_subset, perf_col=perf_col)[\n",
    "    perf_col\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf10e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import draw_bon_k_times\n",
    "\n",
    "np.random.seed(0)\n",
    "perf_vs_samples = pd.DataFrame(\n",
    "    {\"n_samples\": range(1, joint_df_subset[\"run_idx\"].nunique() + 1)}\n",
    ")\n",
    "perf_vs_samples[perf_col] = perf_vs_samples[\"n_samples\"].apply(\n",
    "    draw_bon_k_times, joint_df=joint_df_subset, k=100, performance_col=perf_col\n",
    ")\n",
    "perf_vs_samples = perf_vs_samples.explode(perf_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d453ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = sns.lineplot(data=perf_vs_samples, x=\"n_samples\", y=perf_col, errorbar=\"sd\")\n",
    "axs.grid(alpha=0.5)\n",
    "axs.set_xlabel(\"Number of samples\")\n",
    "axs.set_ylabel(\"Wasserstein Distance\")\n",
    "axs.axhline(y=baseline_perf, color=\"orange\", linestyle=\"--\", label=\"Model Averaging\")\n",
    "axs.axhline(y=oracle_ws_loss, color=\"red\", linestyle=\"--\", label=\"BoN Oracle\")\n",
    "axs.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5427c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# judge_alias = judge.replace(\"/\", \"_\")\n",
    "# perf_vs_samples.assign(judge=judge, dataset=dataset).to_parquet(\n",
    "#     f\"../notebook/tables/bon_samples_vs_perf_nlp/{judge_alias}_{dataset}.parquet\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
