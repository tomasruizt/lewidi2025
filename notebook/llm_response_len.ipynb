{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lewidi_lib import enable_logging\n",
    "\n",
    "enable_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c56ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "from lewidi_lib import preds_file\n",
    "import pandas as pd\n",
    "\n",
    "datasets = [\"MP\", \"CSC\", \"Paraphrase\", \"VariErrNLI\", \"prm800k\", \"aime\"]\n",
    "\n",
    "\n",
    "def qwen32b_preds_file(dataset: str) -> Path:\n",
    "    if is_math(dataset):\n",
    "        run_name = \"allex_10loops\"\n",
    "    else:\n",
    "        run_name = \"1000ex_10loops\"\n",
    "    return preds_file(\n",
    "        dataset=dataset,\n",
    "        split=\"train\",\n",
    "        template=\"60\",\n",
    "        model_id=\"Qwen/Qwen3-32B\",\n",
    "        run_name=run_name,\n",
    "    )\n",
    "\n",
    "\n",
    "judge = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "judge_file_nlp = {\n",
    "    \"gemini-2.5-flash\": \"1000ex_10loops/judge/gemini-2.5-flash/t24/responses.parquet\",\n",
    "    \"Qwen/Qwen3-32B\": \"1000ex_10loops/judge/Qwen/Qwen3-32B/set2/t24/1000ex_10loops_q5div/responses.parquet\",\n",
    "    \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\": \"1000ex_10loops/judge/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B/set2/t24/1000ex_10loops_q5div/responses.parquet\",\n",
    "}\n",
    "judge_to_file_math = {\n",
    "    \"gemini-2.5-flash\": \"allex_10loops_mixed_perf_subset/judge/gemini-2.5-flash/t24/allex_10loops_mp/responses.parquet\",\n",
    "    \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\": \"allex_10loops_mixed_perf_subset/judge/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B/set2/t24/allex_10loops_mp/responses.parquet\",\n",
    "    \"Qwen/Qwen3-32B\": \"allex_10loops_mixed_perf_subset/judge/Qwen/Qwen3-32B/set2/t24/allex_10loops_mp/responses.parquet\",\n",
    "}\n",
    "\n",
    "\n",
    "def judge_to_file(judge, dataset):\n",
    "    if is_math(dataset):\n",
    "        return judge_to_file_math[judge]\n",
    "    else:\n",
    "        return judge_file_nlp[judge]\n",
    "\n",
    "\n",
    "def is_math(dataset: str) -> bool:\n",
    "    return dataset.lower() in [\"prm800k\", \"aime\"]\n",
    "\n",
    "\n",
    "def assign_col_domain(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    col = df[\"dataset\"].apply(lambda x: \"Math\" if is_math(x) else \"Subjective NLP\")\n",
    "    return df.assign(domain=col)\n",
    "\n",
    "\n",
    "preds_files = []\n",
    "judge_files = []\n",
    "for dataset in datasets:\n",
    "    pfile = qwen32b_preds_file(dataset)\n",
    "    preds_files.append(pfile)\n",
    "    assert pfile.exists()\n",
    "    for judge in judge_file_nlp.keys():\n",
    "        judge_file = pfile.parent.parent.parent / judge_to_file(judge, dataset)\n",
    "        assert judge_file.exists(), f\"{judge_file} does not exist\"\n",
    "        judge_files.append(judge_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json_repair\n",
    "from lewidi_lib import assign_col_response_parsed, process_ratings\n",
    "import numpy as np\n",
    "from prm800k import extract_rating, mapping\n",
    "\n",
    "con = duckdb.connect()\n",
    "df = con.sql(\n",
    "    f\"\"\"\n",
    "SELECT dataset, judge_model_id, dataset_idx, run_idx, response, reasoning\n",
    "FROM read_parquet({[str(f) for f in judge_files]}, union_by_name=True)\n",
    "WHERE success = true\n",
    "\"\"\"\n",
    ").df()\n",
    "\n",
    "\n",
    "def extract(x):\n",
    "    try:\n",
    "        return [e[\"rating\"] for e in json_repair.loads(x)]\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "df = assign_col_response_parsed(df)\n",
    "df = process_ratings(df, operation=np.mean, cat_mapping=mapping(ok=0.0, bad=0))\n",
    "df = df.assign(\n",
    "    reasoning_len=df[\"reasoning\"].str.len(),\n",
    "    response_len=df[\"response\"].str.len(),\n",
    ")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfcb9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_rating_data = df.explode(\"step_ratings\").rename(columns={\"step_ratings\": \"rating\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801594db",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    step_rating_data.groupby([\"judge_model_id\", \"dataset\"])[\"rating\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .reset_index()\n",
    "    .query(\"rating == 1\")\n",
    "    .pivot(index=\"judge_model_id\", columns=\"dataset\", values=\"proportion\")\n",
    "    * 100\n",
    ").round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2111160",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_len_df = df.query(\"judge_model_id != 'gemini-2.5-flash'\")\n",
    "cot_len_df.groupby([\"judge_model_id\", \"dataset\"], as_index=False)[\n",
    "    \"reasoning_len\"\n",
    "].mean().pivot(index=\"judge_model_id\", columns=\"dataset\", values=\"reasoning_len\").round(\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef26efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data_judge = df.melt(\n",
    "    id_vars=[\"judge_model_id\", \"dataset\"],\n",
    "    value_vars=[\"response_len\", \"reasoning_len\"],\n",
    "    value_name=\"length\",\n",
    "    var_name=\"block\",\n",
    ").assign(model=\"Judge\")\n",
    "\n",
    "block_names = {\"response_len\": \"response\", \"reasoning_len\": \"reasoning\"}\n",
    "len_data_judge[\"block\"] = len_data_judge[\"block\"].map(block_names)\n",
    "len_data_judge = assign_col_domain(len_data_judge)\n",
    "len_data_judge = len_data_judge.query(\n",
    "    \"judge_model_id != 'gemini-2.5-flash' and block == 'reasoning'\"\n",
    ")\n",
    "model_map = {\n",
    "    \"Qwen/Qwen3-32B\": \"Qwen3-32B\",\n",
    "    \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\": \"DeepSeek-R1-8B\",\n",
    "}\n",
    "ds_map = {\"prm800k\": \"PRM800K\", \"aime\": \"AIME\"}\n",
    "len_data_judge = len_data_judge.assign(\n",
    "    model_id=len_data_judge[\"judge_model_id\"].map(model_map),\n",
    "    dataset=len_data_judge[\"dataset\"].map(lambda s: ds_map.get(s, s)),\n",
    ")\n",
    "len_data_judge[\"title\"] = len_data_judge[\"model\"] + \": \" + len_data_judge[\"model_id\"]\n",
    "len_data_judge.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd00429",
   "metadata": {},
   "source": [
    "# Preds Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b873c471",
   "metadata": {},
   "outputs": [],
   "source": [
    "long = con.sql(\n",
    "    f\"\"\"\n",
    "SELECT dataset, model_id, dataset_idx, run_idx, response, reasoning\n",
    "FROM read_parquet({[str(f) for f in preds_files]}, union_by_name=True)\n",
    "WHERE success = true\n",
    "\"\"\"\n",
    ").df()\n",
    "\n",
    "long = long.assign(model_id=long[\"model_id\"].map(model_map))\n",
    "long = long.assign(\n",
    "    response_len=long[\"response\"].apply(len),\n",
    "    reasoning_len=long[\"reasoning\"].apply(len),\n",
    ")\n",
    "len_data_preds = long.melt(\n",
    "    id_vars=[\"model_id\", \"dataset\"],\n",
    "    value_vars=[\"response_len\", \"reasoning_len\"],\n",
    "    value_name=\"length\",\n",
    "    var_name=\"block\",\n",
    ").assign(model=\"LLM\")\n",
    "len_data_preds[\"block\"] = len_data_preds[\"block\"].map(block_names)\n",
    "len_data_preds[\"dataset\"] = len_data_preds[\"dataset\"].map(lambda x: ds_map.get(x, x))\n",
    "len_data_preds[\"title\"] = len_data_preds[\"model\"] + \": \" + len_data_preds[\"model_id\"]\n",
    "len_data_preds = assign_col_domain(len_data_preds)\n",
    "len_data_preds.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df458847",
   "metadata": {},
   "outputs": [],
   "source": [
    "long.groupby([\"dataset\"], as_index=False).agg(\n",
    "    response=(\"response_len\", \"mean\"),\n",
    "    reasoning=(\"reasoning_len\", \"mean\"),\n",
    ").round(0).melt(id_vars=[\"dataset\"], var_name=\"type\", value_name=\"length\").pivot(\n",
    "    index=\"dataset\", columns=\"type\", values=\"length\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e62c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_data = len_data_preds.query(\"block == 'reasoning'\")\n",
    "judge_data = len_data_judge[preds_data.columns]\n",
    "joint_data = pd.concat([preds_data, judge_data], ignore_index=True)\n",
    "joint_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15101a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "\n",
    "def plot_num_chars(len_data):\n",
    "    fgrid = sns.catplot(\n",
    "        len_data,\n",
    "        y=\"dataset\",\n",
    "        x=\"length\",\n",
    "        hue=\"domain\",\n",
    "        kind=\"bar\",\n",
    "        col=\"title\",\n",
    "        # showfliers=False,\n",
    "        margin_titles=True,\n",
    "        errorbar=lambda x: (np.quantile(x, 0.25), np.quantile(x, 0.75)),\n",
    "        sharex=False,\n",
    "        aspect=0.8,\n",
    "    )\n",
    "    fgrid.set_titles(col_template=\"{col_name}\")\n",
    "    fgrid.set_axis_labels(\"Number of Chars\", \"Dataset\")\n",
    "    sns.move_legend(\n",
    "        fgrid, loc=\"lower left\", bbox_to_anchor=(0.3, 1.0), ncol=2, title=\"Domain\"\n",
    "    )\n",
    "    for ax in fgrid.axes.flat:\n",
    "        ax.grid(alpha=0.5, axis=\"x\")\n",
    "    return fgrid\n",
    "\n",
    "\n",
    "fgrid = plot_num_chars(joint_data)\n",
    "\n",
    "fgrid.savefig(\n",
    "    \"imgs/domain_comp/lens-of-responses-and-reasonings.pdf\", bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2be968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fgrid = sns.catplot(\n",
    "#     len_data_judge,\n",
    "#     y=\"dataset\",\n",
    "#     x=\"length\",\n",
    "#     kind=\"box\",\n",
    "#     hue=\"domain\",\n",
    "#     col=\"model_id\",\n",
    "#     showfliers=False,\n",
    "#     errorbar=lambda x: (np.quantile(x, 0.25), np.quantile(x, 0.75)),\n",
    "#     sharex=False,\n",
    "#     margin_titles=True,\n",
    "# )\n",
    "# fgrid.set_axis_labels(\"Number of Chars\", \"Dataset\")\n",
    "# sns.move_legend(\n",
    "#     fgrid, loc=\"lower left\", bbox_to_anchor=(0.3, 1.0), ncol=2, title=\"Domain\"\n",
    "# )\n",
    "# fgrid.set_titles(col_template=\"{col_name}\")\n",
    "# for ax in fgrid.axes.flat:\n",
    "#     ax.grid(alpha=0.5, axis=\"x\")\n",
    "# fgrid.savefig(\"imgs/domain_comp/lens-of-reasonings-judge.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
