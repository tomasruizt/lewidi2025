{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f079078",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lewidi_lib import enable_logging\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "enable_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136c964",
   "metadata": {},
   "source": [
    "# Math Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = duckdb.sql(\"SELECT * FROM read_parquet('./tables/bon_samples_vs_perf/*')\").df()\n",
    "df = df.drop(columns=[\"__index_level_0__\"])\n",
    "df[\"Judge\"] = df[\"judge\"].apply(lambda s: s.split(\"/\")[-1])\n",
    "df[\"Dataset\"] = df[\"dataset\"].apply(lambda s: s.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ccbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def quantiles(xs):\n",
    "    return np.quantile(xs, 0.1), np.quantile(xs, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import plot_horizontal_lines\n",
    "\n",
    "fgrid = sns.relplot(\n",
    "    df,\n",
    "    x=\"n_samples\",\n",
    "    y=\"is_correct\",\n",
    "    col=\"Dataset\",\n",
    "    col_order=[\"PRM800K\", \"AIME\"],\n",
    "    hue=\"Judge\",\n",
    "    style=\"Judge\",\n",
    "    markers=[\"o\", \"s\", \"D\", \"P\"],\n",
    "    kind=\"line\",\n",
    "    facet_kws={\"sharey\": False},\n",
    "    # errorbar=quantiles,\n",
    ")\n",
    "fgrid.set_axis_labels(\"LLM samples $N$\", \"Correct answers\")\n",
    "sns.move_legend(fgrid, loc=\"lower left\", bbox_to_anchor=(0.05, 0.95), ncol=3)\n",
    "for ax in fgrid.axes.flat:\n",
    "    ax.grid(alpha=0.5)\n",
    "\n",
    "data = pd.DataFrame({\"Dataset\": [\"PRM800K\", \"AIME\"], \"is_correct\": [0.721, 0.639]})\n",
    "plot_horizontal_lines(\n",
    "    fgrid, data, label=\"Qwen3-32B Simple Sampling\", color=\"blue\", data_col=\"is_correct\"\n",
    ")\n",
    "\n",
    "fgrid.savefig(\"./imgs/bon-eval/bon_samples_vs_perf_math.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de0342",
   "metadata": {},
   "source": [
    "# NLP Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84676b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnlp = duckdb.sql(\n",
    "    \"SELECT * FROM read_parquet('./tables/bon_samples_vs_perf_nlp/*')\"\n",
    ").df()\n",
    "dfnlp = dfnlp.drop(columns=[\"__index_level_0__\"])\n",
    "dfnlp[\"Judge\"] = dfnlp[\"judge\"].apply(lambda s: s.split(\"/\")[-1])\n",
    "dfnlp[\"Dataset\"] = dfnlp[\"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69943c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgrid = sns.relplot(\n",
    "    dfnlp,\n",
    "    x=\"n_samples\",\n",
    "    y=\"ws_loss\",\n",
    "    col=\"Dataset\",\n",
    "    col_wrap=2,\n",
    "    hue=\"Judge\",\n",
    "    style=\"Judge\",\n",
    "    markers=[\"o\", \"s\", \"D\", \"P\"],\n",
    "    kind=\"line\",\n",
    "    facet_kws={\"sharey\": False},\n",
    "    height=4.0,\n",
    "    aspect=1.2,\n",
    "    # errorbar=quantiles\n",
    ")\n",
    "fgrid.set_axis_labels(\"LLM samples $N$\", \"Wasserstein Distance\")\n",
    "sns.move_legend(fgrid, loc=\"lower left\", bbox_to_anchor=(0.25, 1.0))\n",
    "for ax in fgrid.axes.flat:\n",
    "    ax.grid(alpha=0.5)\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"Dataset\": [\"CSC\", \"MP\", \"Paraphrase\", \"VariErrNLI\"],\n",
    "        \"ws_loss\": [1.175, 0.296, 2.48, 0.293],\n",
    "    }\n",
    ")\n",
    "plot_horizontal_lines(\n",
    "    fgrid, data, label=\"Qwen3-32B Simple Sampling\", color=\"blue\", data_col=\"ws_loss\"\n",
    ")\n",
    "\n",
    "fgrid.savefig(\"./imgs/bon-eval/bon_samples_vs_perf_nlp.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
