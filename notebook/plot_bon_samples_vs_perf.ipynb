{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f079078",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from lewidi_lib import enable_logging\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "enable_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136c964",
   "metadata": {},
   "source": [
    "# Math Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import compact_model_name\n",
    "\n",
    "\n",
    "df = duckdb.sql(\"SELECT * FROM read_parquet('./tables/bon_samples_vs_perf/*')\").df()\n",
    "df = df.drop(columns=[\"__index_level_0__\"])\n",
    "df[\"Judge\"] = df[\"judge\"].apply(compact_model_name)\n",
    "df[\"Dataset\"] = df[\"dataset\"].apply(lambda s: s.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ccbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def quantiles(xs):\n",
    "    return np.quantile(xs, 0.25), np.quantile(xs, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import plot_horizontal_lines\n",
    "\n",
    "fgrid = sns.relplot(\n",
    "    df,\n",
    "    x=\"n_samples\",\n",
    "    y=\"is_correct\",\n",
    "    col=\"Dataset\",\n",
    "    col_order=[\"PRM800K\", \"AIME\"],\n",
    "    hue=\"Judge\",\n",
    "    style=\"Judge\",\n",
    "    markers=[\"o\", \"s\", \"D\", \"P\"],\n",
    "    kind=\"line\",\n",
    "    facet_kws={\"sharey\": False},\n",
    "    height=4,\n",
    "    aspect=1.2,\n",
    "    errorbar=quantiles,\n",
    ")\n",
    "fgrid.set_axis_labels(\"LLM samples $N$\", \"Correct answers\")\n",
    "sns.move_legend(fgrid, loc=\"lower left\", bbox_to_anchor=(0.1, 0.95), ncol=3)\n",
    "for ax in fgrid.axes.flat:\n",
    "    ax.grid(alpha=0.5)\n",
    "\n",
    "data = pd.DataFrame({\"Dataset\": [\"PRM800K\", \"AIME\"], \"is_correct\": [0.721, 0.639]})\n",
    "plot_horizontal_lines(\n",
    "    fgrid,\n",
    "    data,\n",
    "    label=\"Simple Sampling\",\n",
    "    color=\"blue\",\n",
    "    data_col=\"is_correct\",\n",
    "    hpos=\"right\",\n",
    "    fontsize=16,\n",
    ")\n",
    "\n",
    "fgrid.savefig(\"./imgs/bon-eval/bon_samples_vs_perf_math.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de0342",
   "metadata": {},
   "source": [
    "# NLP Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84676b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import compact_model_name, rename_dataset\n",
    "\n",
    "\n",
    "sldf = (\n",
    "    duckdb.sql(\"SELECT * FROM read_parquet('./tables/bon_samples_vs_perf_nlp_t60/*')\")\n",
    "    .df()\n",
    "    .query(\"judge != 'gemini-2.5-flash'\")\n",
    ")\n",
    "sldf = sldf.drop(columns=[\"__index_level_0__\"])\n",
    "sldf[\"Judge\"] = sldf[\"judge\"].apply(compact_model_name)\n",
    "sldf = rename_dataset(sldf, col=\"dataset\")\n",
    "sldf[\"Dataset\"] = sldf[\"dataset\"]\n",
    "sldf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import rename_dataset\n",
    "\n",
    "sl_model_averaging_df = (\n",
    "    pd.read_csv(\"./tables/soft-label/32b_ws_loss.csv\")\n",
    "    .query(\"Baseline == 'Model Averaging'\")\n",
    "    .melt(id_vars=\"Baseline\", var_name=\"Dataset\", value_name=\"ws_loss\")\n",
    ")\n",
    "sl_simple_sampling_df = (\n",
    "    sldf.query(\"n_samples == 1\")\n",
    "    .groupby(\"Dataset\", as_index=False)[\"ws_loss\"]\n",
    "    .mean()\n",
    "    .assign(Baseline=\"Simple Sampling\")\n",
    ")\n",
    "\n",
    "sl_hlines_df = pd.concat([sl_model_averaging_df, sl_simple_sampling_df])\n",
    "sl_hlines_df = rename_dataset(sl_hlines_df, col=\"Dataset\")\n",
    "sl_hlines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69943c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bon_scaling(\n",
    "    df,\n",
    "    hlines_df,\n",
    "    perf_col: str,\n",
    "    scaling_method: str,\n",
    "    dist1_label: str,\n",
    "    dist2_label: str,\n",
    "    sharey: bool,\n",
    "):\n",
    "    datasets = [\"CSC\", \"PAR\", \"MP\", \"VEN\"]\n",
    "    fgrid = sns.relplot(\n",
    "        df,\n",
    "        x=\"n_samples\",\n",
    "        y=perf_col,\n",
    "        col=\"Dataset\",\n",
    "        col_wrap=2,\n",
    "        col_order=datasets,\n",
    "        hue=\"Judge\",\n",
    "        style=\"Judge\",\n",
    "        markers=[\"o\", \"s\", \"D\", \"P\"],\n",
    "        kind=\"line\",\n",
    "        facet_kws={\"sharey\": sharey},\n",
    "        height=3.5,\n",
    "        aspect=1.5,\n",
    "        errorbar=quantiles,\n",
    "    )\n",
    "    fgrid.set_axis_labels(\"LLM samples $N$\", dist1_label)\n",
    "    sns.move_legend(fgrid, loc=\"lower left\", bbox_to_anchor=(0.2, 1.0), ncol=2)\n",
    "    for ax in fgrid.axes.flat:\n",
    "        ax.grid(alpha=0.5)\n",
    "    fgrid.axes[2].set_ylabel(dist2_label)\n",
    "\n",
    "    hlines_fontsize = 16\n",
    "    plot_horizontal_lines(\n",
    "        fgrid,\n",
    "        hlines_df.query(\"Baseline == 'Simple Sampling'\"),\n",
    "        label=\"Simple Sampling\",\n",
    "        color=\"blue\",\n",
    "        data_col=perf_col,\n",
    "        fontsize=hlines_fontsize,\n",
    "    )\n",
    "    plot_horizontal_lines(\n",
    "        fgrid,\n",
    "        hlines_df.query(f\"Baseline == '{scaling_method}'\"),\n",
    "        label=scaling_method,\n",
    "        color=\"red\",\n",
    "        data_col=perf_col,\n",
    "        fontsize=hlines_fontsize,\n",
    "    )\n",
    "\n",
    "    return fgrid\n",
    "\n",
    "\n",
    "fgrid = plot_bon_scaling(\n",
    "    df=rename_dataset(sldf),\n",
    "    hlines_df=sl_hlines_df,\n",
    "    perf_col=\"ws_loss\",\n",
    "    scaling_method=\"Model Averaging\",\n",
    "    dist1_label=\"Wasserstein Distance\",\n",
    "    dist2_label=\"Manhattan Distance\",\n",
    "    sharey=False,\n",
    ")\n",
    "fgrid.savefig(\"./imgs/bon-eval/bon_samples_vs_perf_nlp_t60.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf304657",
   "metadata": {},
   "source": [
    "# Perspectivist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21be4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "pedf = (\n",
    "    duckdb.sql(\"SELECT * FROM read_parquet('./tables/bon_samples_vs_perf_nlp_t63/*')\")\n",
    "    .df()\n",
    "    .query(\"judge != 'gemini-2.5-flash'\")\n",
    ")\n",
    "pedf = pedf.drop(columns=[\"__index_level_0__\"])\n",
    "pedf[\"Judge\"] = pedf[\"judge\"].apply(compact_model_name)\n",
    "pedf = rename_dataset(pedf, col=\"dataset\")\n",
    "pedf[\"Dataset\"] = pedf[\"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_reference = \"Majority Vote\"\n",
    "pe_model_averaging_df = (\n",
    "    pd.read_csv(\"./tables/perspectivist/32b_avg_abs_dist.csv\")\n",
    "    .query(f\"Baseline == '{pe_reference}'\")\n",
    "    .melt(id_vars=\"Baseline\", var_name=\"Dataset\", value_name=\"avg_abs_dist\")\n",
    ")\n",
    "pe_simple_sampling_df = (\n",
    "    pedf.query(\"n_samples == 1\")\n",
    "    .groupby(\"Dataset\", as_index=False)[\"avg_abs_dist\"]\n",
    "    .mean()\n",
    "    .assign(Baseline=\"Simple Sampling\")\n",
    ")\n",
    "\n",
    "pe_hlines_df = pd.concat([pe_model_averaging_df, pe_simple_sampling_df])\n",
    "pe_hlines_df = rename_dataset(pe_hlines_df, col=\"Dataset\")\n",
    "pe_hlines_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e151aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fgrid = plot_bon_scaling(\n",
    "    pedf,\n",
    "    hlines_df=pe_hlines_df,\n",
    "    perf_col=\"avg_abs_dist\",\n",
    "    scaling_method=pe_reference,\n",
    "    dist1_label=\"Absolute Distance\",\n",
    "    dist2_label=\"Error Rate\",\n",
    "    sharey=False,\n",
    ")\n",
    "fgrid.savefig(\"./imgs/bon-eval/bon_samples_vs_perf_nlp_t63.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a476ef",
   "metadata": {},
   "source": [
    "# Perf tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aff18fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    sldf.query(\"n_samples == 10\")\n",
    "    .groupby([\"judge\", \"dataset\"])\n",
    "    .agg({\"ws_loss\": \"mean\"})\n",
    "    .reset_index()\n",
    "    .round(3)\n",
    "    .to_csv(\"./tables/soft-label/32b_bon_ws_loss.csv\", index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4490c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pedf.query(\"n_samples == 10\")\n",
    "    .groupby([\"judge\", \"dataset\"])\n",
    "    .agg({\"avg_abs_dist\": \"mean\"})\n",
    "    .reset_index()\n",
    "    .round(3)\n",
    "    .to_csv(\"./tables/perspectivist/32b_bon_avg_abs_dist.csv\", index=False)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
