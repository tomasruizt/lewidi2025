{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de259b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b5533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from lewidi_lib import (\n",
    "    discard_failed_rows,\n",
    "    discard_na_response_rows,\n",
    "    enable_logging,\n",
    "    join_dataset,\n",
    "    preds_file,\n",
    ")\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "enable_logging()\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "\n",
    "def is_response_valid(response: dict) -> bool:\n",
    "    return isinstance(response, dict) and \"final_response\" in response\n",
    "\n",
    "\n",
    "rdf = pd.read_parquet(\"../prm800k-poc/preds/responses.parquet\")\n",
    "rdf = discard_failed_rows(rdf)\n",
    "rdf = discard_na_response_rows(rdf)\n",
    "rdf[\"response_parsed\"] = rdf[\"response\"].apply(json_repair.loads)\n",
    "rdf[\"pred\"] = rdf[\"response_parsed\"].apply(lambda x: x[\"final_response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25def94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct = pd.read_parquet(\"../prm800k-poc/judge/verify-solution/responses.parquet\")\n",
    "is_correct = discard_na_response_rows(is_correct)\n",
    "is_correct = is_correct[[\"dataset_idx\", \"run_idx\", \"response\", \"reasoning\"]].rename(\n",
    "    columns={\"response\": \"is_correct\", \"reasoning\": \"is_correct_reasoning\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import assign_col_response_parsed, process_ratings\n",
    "import numpy as np\n",
    "from prm800k import mapping\n",
    "\n",
    "ratings = pd.read_parquet(\"../prm800k-poc/judge/gemini-2.5-flash/responses.parquet\")\n",
    "ratings = discard_na_response_rows(ratings)\n",
    "ratings = assign_col_response_parsed(ratings)\n",
    "ratings = process_ratings(\n",
    "    ratings, operation=np.prod, cat_mapping=mapping(ok=0.0, bad=0)\n",
    ")\n",
    "ratings = ratings[[\"dataset_idx\", \"run_idx\", \"score\", \"reasoning\"]]\n",
    "ratings.rename(columns={\"reasoning\": \"judge_reasoning\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90994ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_df = join_dataset(rdf, parse_tgt=False)\n",
    "joint_df = joint_df.merge(ratings, on=[\"dataset_idx\", \"run_idx\"], how=\"left\").merge(\n",
    "    is_correct, on=[\"dataset_idx\", \"run_idx\"]\n",
    ")\n",
    "joint_df = discard_na_response_rows(joint_df, col=\"score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f86b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = joint_df.groupby(\"score\", as_index=False).agg(\n",
    "    is_correct=(\"is_correct\", \"mean\"), n_examples=(\"dataset_idx\", \"count\")\n",
    ")\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf78a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(corr_df, x=\"score\", y=\"is_correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ = joint_df.groupby(\"dataset_idx\")\n",
    "g_[[\"score\", \"is_correct\"]].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaedb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score_df = joint_df.loc[joint_df.groupby(\"dataset_idx\")[\"score\"].idxmax()]\n",
    "max_score_df[[\"score\", \"is_correct\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "\n",
    "crosstab = duckdb.sql(\"PIVOT joint_df ON is_correct GROUP BY dataset_idx\").df()\n",
    "crosstab = crosstab.rename(columns={\"0\": \"incorrect\", \"1\": \"correct\"})\n",
    "crosstab[\"all_incorrect\"] = (crosstab[\"incorrect\"] > 0) & (crosstab[\"correct\"] == 0)\n",
    "crosstab[\"all_correct\"] = (crosstab[\"incorrect\"] == 0) & (crosstab[\"correct\"] > 0)\n",
    "crosstab[\"mixed\"] = (crosstab[\"incorrect\"] > 0) & (crosstab[\"correct\"] > 0)\n",
    "assert crosstab[[\"all_incorrect\", \"all_correct\", \"mixed\"]].sum().sum() == len(crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11ac862",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab.melt(\n",
    "    \"dataset_idx\", value_vars=[\"all_incorrect\", \"all_correct\", \"mixed\"], var_name=\"type\"\n",
    ").query(\"value\")[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552a43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixd_perf = crosstab.query(\"mixed\")\n",
    "mixd_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba39bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_df.query(\"dataset_idx == 55\")[\n",
    "    [\n",
    "        \"run_idx\",\n",
    "        \"pred\",\n",
    "        \"target\",\n",
    "        \"is_correct\",\n",
    "        \"score\",\n",
    "        \"response\",\n",
    "        \"is_correct_reasoning\",\n",
    "        \"judge_reasoning\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a9e99f",
   "metadata": {},
   "source": [
    "# Mixed Perf Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136cee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import bootstrap_avg\n",
    "\n",
    "\n",
    "mp_cases = joint_df.query(\"dataset_idx in @mixd_perf.dataset_idx\")\n",
    "mp_cases.groupby(\"dataset_idx\")[[\"score\", \"is_correct\"]].mean().apply(bootstrap_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf18635",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_cases_bon = mp_cases.loc[mp_cases.groupby(\"dataset_idx\")[\"score\"].idxmax()]\n",
    "mp_cases_bon[[\"score\", \"is_correct\"]].apply(bootstrap_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfaeaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(df):\n",
    "    coeff = np.corrcoef(df[\"score\"], df[\"is_correct\"])[0, 1]\n",
    "    return coeff\n",
    "mp_cases.groupby(\"dataset_idx\").apply(corr).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
