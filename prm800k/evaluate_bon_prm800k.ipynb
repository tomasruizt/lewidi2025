{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de259b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload \n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f02ce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_response_valid(response: dict) -> bool:\n",
    "    return isinstance(response, dict) and \"final_response\" in response\n",
    "\n",
    "\n",
    "def extract_final_response(d: dict) -> str:\n",
    "    if \"final_response\" not in d:\n",
    "        return None\n",
    "    return d[\"final_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88b5533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from lewidi_lib import (\n",
    "    discard_failed_rows,\n",
    "    discard_na_response_rows,\n",
    "    drop_duplicates_in_ds_idx_run_idx,\n",
    "    enable_logging,\n",
    "    join_dataset,\n",
    "    preds_file,\n",
    "    recompute_success,\n",
    ")\n",
    "import pandas as pd\n",
    "import json_repair\n",
    "\n",
    "enable_logging()\n",
    "logger = getLogger(__name__)\n",
    "\n",
    "dataset = \"prm800k\"\n",
    "file = preds_file(\n",
    "    dataset=dataset,\n",
    "    split=\"train\",\n",
    "    template=\"60\",\n",
    "    model_id=\"Qwen/Qwen3-32B\",\n",
    "    run_name=\"allex_10loops\",\n",
    ")\n",
    "rdf = pd.read_parquet(file)\n",
    "logger.info(\"rdf has %d rows\", len(rdf))\n",
    "rdf = recompute_success(rdf)\n",
    "rdf = discard_failed_rows(rdf)\n",
    "rdf = discard_na_response_rows(rdf)\n",
    "rdf[\"response_parsed\"] = rdf[\"response\"].apply(json_repair.loads)\n",
    "rdf[\"pred\"] = rdf[\"response_parsed\"].apply(extract_final_response)\n",
    "rdf = discard_na_response_rows(rdf, col=\"pred\")\n",
    "rdf = drop_duplicates_in_ds_idx_run_idx(rdf)\n",
    "logger.info(\n",
    "    \"rdf has %d rows for %d different dataset_idx\",\n",
    "    len(rdf),\n",
    "    rdf[\"dataset_idx\"].nunique(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25def94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_correct_file = (\n",
    "    file.parent.parent\n",
    "    / \"judge\"\n",
    "    / \"Qwen/Qwen3-14B\"\n",
    "    / \"set2\"\n",
    "    / \"t60\"\n",
    "    / \"allex_10loops\"\n",
    "    / \"responses.parquet\"\n",
    ")\n",
    "is_correct = pd.read_parquet(is_correct_file)\n",
    "logger.info(\n",
    "    \"Loaded %d is_correct rows for %d different dataset_idxs\",\n",
    "    len(is_correct),\n",
    "    is_correct[\"dataset_idx\"].nunique(),\n",
    ")\n",
    "is_correct = discard_na_response_rows(is_correct)\n",
    "is_correct = is_correct[\n",
    "    [\"dataset\", \"dataset_idx\", \"run_idx\", \"response\", \"reasoning\"]\n",
    "].rename(columns={\"response\": \"is_correct\", \"reasoning\": \"is_correct_reasoning\"})\n",
    "is_correct = is_correct.astype({\"is_correct\": \"int\"})\n",
    "is_correct = drop_duplicates_in_ds_idx_run_idx(is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import compute_is_correct_crosstab\n",
    "\n",
    "perf_ct = compute_is_correct_crosstab(is_correct, long=True)\n",
    "perf_ct[\"correct_level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfccc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import duckdb\n",
    "\n",
    "\n",
    "# mixed_perf = perf_ct.query(\"correct_level == 'mixed'\")\n",
    "# tgt_mp_file = file.parent.parent.parent / \"allex_10loops_mixed_perf_subset\" / \"preds\" / \"ids.parquet\"\n",
    "# tgt_responses_file = tgt_mp_file.parent / \"responses.parquet\"\n",
    "# tgt_mp_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "# mixed_perf.to_parquet(tgt_mp_file, index=False)\n",
    "\n",
    "# sql = f\"\"\"\n",
    "# COPY (\n",
    "#     SELECT rdf.*\n",
    "#     FROM '{str(file)}' as rdf\n",
    "#     JOIN (\n",
    "#         SELECT *\n",
    "#         FROM '{str(tgt_mp_file)}'\n",
    "#         WHERE success = true\n",
    "#     ) as ids ON rdf.dataset_idx = ids.dataset_idx\n",
    "# ) TO '{str(tgt_responses_file)}';\n",
    "# \"\"\"\n",
    "# duckdb.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf9305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import bootstrap_avg\n",
    "\n",
    "joint_df = join_dataset(rdf, parse_tgt=False)\n",
    "joint_df = joint_df.merge(is_correct, on=[\"dataset\", \"dataset_idx\", \"run_idx\"])\n",
    "joint_df = joint_df.merge(perf_ct.query(\"correct_level == 'mixed'\"), on=\"dataset_idx\")\n",
    "assert len(joint_df) > 0\n",
    "logger.info(\"joint_df has %d different dataset_idx\", joint_df[\"dataset_idx\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673098e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_file = \"/Users/tomasruiz/datasets/dss_home/lewidi-data/sbatch/di38bec/Qwen_Qwen3-32B/set2/t60/prm800k/train/1000ex_10loops_mixed_perf_subset/judge/gemini-2.5-flash/responses.parquet\"\n",
    "# ratings_file = \"/Users/tomasruiz/datasets/dss_home/lewidi-data/sbatch/di38bec/Qwen_Qwen3-32B/set2/t60/prm800k/train/1000ex_10loops_mixed_perf_subset/judge/Qwen/Qwen3-32B/set2/t23/1000ex_10loops/responses.parquet\"\n",
    "# ratings_file = \"/Users/tomasruiz/datasets/dss_home/lewidi-data/sbatch/di38bec/Qwen_Qwen3-32B/set2/t60/prm800k/train/1000ex_10loops_mixed_perf_subset/judge/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B/set2/t23/1000ex_10loops/responses.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff8f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import assign_col_response_parsed, process_ratings\n",
    "import numpy as np\n",
    "from prm800k import mapping\n",
    "import pandas as pd\n",
    "\n",
    "judge = \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\"\n",
    "# judge = \"gemini-2.5-flash\"\n",
    "# judge = \"Qwen/Qwen3-32B\"\n",
    "judge_to_file = {\n",
    "    \"gemini-2.5-flash\": \"allex_10loops_mixed_perf_subset/judge/gemini-2.5-flash/t24/allex_10loops_mp/responses.parquet\",\n",
    "    \"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B\": \"allex_10loops_mixed_perf_subset/judge/deepseek-ai/DeepSeek-R1-0528-Qwen3-8B/set2/t24/allex_10loops_mp/responses.parquet\",\n",
    "    \"Qwen/Qwen3-32B\": \"allex_10loops_mixed_perf_subset/judge/Qwen/Qwen3-32B/set2/t24/allex_10loops_mp/responses.parquet\",\n",
    "}\n",
    "ratings_file = file.parent.parent.parent / judge_to_file[judge]\n",
    "ratings = pd.read_parquet(ratings_file)\n",
    "ratings = recompute_success(ratings)\n",
    "ratings = discard_failed_rows(ratings)\n",
    "logger.info(\n",
    "    \"Loaded %d ratings for %d different dataset_idx\",\n",
    "    len(ratings),\n",
    "    len(ratings[\"dataset_idx\"].unique()),\n",
    ")\n",
    "ratings = discard_na_response_rows(ratings)\n",
    "ratings = assign_col_response_parsed(ratings)\n",
    "ratings = process_ratings(\n",
    "    ratings, operation=np.mean, cat_mapping=mapping(ok=0.0, bad=0)\n",
    ")\n",
    "ratings.rename(columns={\"reasoning\": \"judge_reasoning\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90994ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_cols = [\n",
    "    \"dataset\",\n",
    "    \"dataset_idx\",\n",
    "    \"run_idx\",\n",
    "    \"step_ratings\",\n",
    "    \"score\",\n",
    "    \"judge_reasoning\",\n",
    "]\n",
    "joint_df = joint_df.merge(\n",
    "    ratings[ratings_cols], on=[\"dataset\", \"dataset_idx\", \"run_idx\"], how=\"left\"\n",
    ")\n",
    "joint_df = discard_na_response_rows(joint_df, col=\"score\")\n",
    "assert len(joint_df) != 0\n",
    "joint_df = joint_df.drop_duplicates(subset=[\"dataset_idx\", \"run_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import compute_n_steps_equality\n",
    "\n",
    "\n",
    "compute_n_steps_equality(joint_df, step_source=\"response_parsed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf78a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "sns.lmplot(joint_df, x=\"score\", y=\"is_correct\", logistic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac27a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(joint_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "bootstrap_avg(\n",
    "    [\n",
    "        joint_df.groupby(\"dataset_idx\").sample(n=1)[\"is_correct\"].mean()\n",
    "        for _ in range(100)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb45599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is randomness due to multiple preds being \"the best\", so we choose one randomly\n",
    "from lewidi_lib import select_max_score_df\n",
    "\n",
    "np.random.seed(0)\n",
    "bootstrap_avg(\n",
    "    [\n",
    "        select_max_score_df(joint_df.sample(frac=1.0))[\"is_correct\"].mean()\n",
    "        for _ in range(20)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfaeaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(df):\n",
    "    coeff = np.corrcoef(df[\"score\"], df[\"is_correct\"])[0, 1]\n",
    "    return coeff\n",
    "\n",
    "\n",
    "bootstrap_avg(\n",
    "    joint_df.groupby(\"dataset_idx\")[[\"score\", \"is_correct\"]].apply(corr).fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7d76b",
   "metadata": {},
   "source": [
    "# Does the Reduction Operation Matter?\n",
    "Using Ok=0 rather than Ok=1 helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64984c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import create_rating_matrix\n",
    "\n",
    "\n",
    "perf_data = ratings.merge(is_correct, on=[\"dataset\", \"dataset_idx\", \"run_idx\"])\n",
    "create_rating_matrix(perf_data, performance_col=\"is_correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6e36b2",
   "metadata": {},
   "source": [
    "# Aggregate Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66edcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(joint_df, x=\"score\")\n",
    "ax.grid(alpha=0.5, axis=\"y\")\n",
    "ax.figure.set_size_inches(6, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb04ae7",
   "metadata": {},
   "source": [
    "# How Does BoN improve performance with more samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lewidi_lib import draw_bon_k_times\n",
    "\n",
    "np.random.seed(0)\n",
    "perf_vs_samples = pd.DataFrame({\"n_samples\": range(1, 11)})\n",
    "perf_vs_samples[\"is_correct\"] = perf_vs_samples[\"n_samples\"].apply(\n",
    "    draw_bon_k_times, joint_df=joint_df, k=100\n",
    ")\n",
    "perf_vs_samples = perf_vs_samples.explode(\"is_correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28bd23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = sns.lineplot(data=perf_vs_samples, x=\"n_samples\", y=\"is_correct\")\n",
    "axs.grid(alpha=0.5)\n",
    "axs.set_xlabel(\"Number of samples\")\n",
    "axs.set_ylabel(\"Correct Answers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86095e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_alias = judge.replace(\"/\", \"_\")\n",
    "perf_vs_samples.assign(judge=judge, dataset=dataset).to_parquet(\n",
    "    f\"../notebook/tables/bon_samples_vs_perf/{judge_alias}_{dataset}.parquet\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
